{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "_EPSILON = 1e-08\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controls (Set then rerun notebook).\n",
    "# MICE vs NON-MICE.\n",
    "USE_MICE_VERSION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_MICE_VERSION:\n",
    "    data_processed_dir = \"after imputation\"\n",
    "    out_dir = \"version1 (integrated)\"\n",
    "else:\n",
    "    data_processed_dir = \"after imputation (MICE)\"\n",
    "    out_dir = \"version1 (integrated) (MICE)\"\n",
    "\n",
    "_out_dir = f'./data/processed/final/{out_dir}/'\n",
    "if not os.path.exists(_out_dir):\n",
    "    os.makedirs(_out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s  = pd.read_csv(f'./data/processed/{data_processed_dir}/baseline.csv')\n",
    "df_t  = pd.read_csv(f'./data/processed/{data_processed_dir}/temporal.csv')\n",
    "df_t  = df_t.drop_duplicates(subset=['New ID', 'Days Since Diagnosis'], keep='last').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = df_t.drop_duplicates(subset=['New ID',], keep='first')[['Days Since Diagnosis']]\n",
    "diff  = df_t['Days Since Diagnosis'].diff()\n",
    "diff[first.index] = first['Days Since Diagnosis']\n",
    "\n",
    "time  = df_t[['New ID', 'Days Since Diagnosis']]\n",
    "\n",
    "df_t['Days Since Diagnosis'] = diff\n",
    "df_t = df_t.rename(columns={'Days Since Diagnosis': 'Delta'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_static = [\n",
    "    'Exact age at diagnosis', 'Number of negative biopsies before diagnosis',\n",
    "    'Number of MRI-visible lesions', 'Ethnicity', 'Family History of Prostate Cancer',\n",
    "    'CPG', 'PI-RADS score', 'STRATCANS (simplified)',\n",
    "]\n",
    "\n",
    "feat_timevarying = [\n",
    "     'Delta', 'Repeat PSA',\n",
    "     'Repeat Biopsy Core Total', 'Repeat Biopsy Core Positive', 'Repeat Biopsy Primary Gleason', \n",
    "     'Repeat Biopsy Secondary Gleason', 'Repeat Biopsy Grade Group',\n",
    "     'Repeat MRI PRECISE Scoring', 'Repeat MRI Stage','Repeat MRI Volume', 'Repeat MRI PSAd'\n",
    "]\n",
    "\n",
    "feat_label = [\n",
    "    'Coding.3', 'Days since diagnosis.3'\n",
    "]\n",
    "\n",
    "\n",
    "xt_bin_list = []\n",
    "xt_con_list = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "\n",
    "data_s = df_s[['New ID'] + feat_static]\n",
    "data_t = df_t[['New ID'] + feat_timevarying]\n",
    "label  = df_s[['New ID'] + feat_label]\n",
    "\n",
    "data_s = data_s[data_s['New ID'].isin(data_t['New ID'].unique())].reset_index(drop=True)\n",
    "label  = label[label['New ID'].isin(data_t['New ID'].unique())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_s                 = MinMaxScaler()\n",
    "scaler_t                 = MinMaxScaler()\n",
    "\n",
    "data_t.loc[data_t['Delta'] == 0, 'Delta'] = 1. #0 makes -inf!\n",
    "data_t['Delta']          = np.log(data_t['Delta'])  ### this is to deal with very skewed deltas...\n",
    "data_s[feat_static]      = scaler_s.fit_transform(data_s[feat_static])\n",
    "data_t[feat_timevarying] = scaler_t.fit_transform(data_t[feat_timevarying])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs     = np.asarray(data_s)[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list    = data_t['New ID'].unique()\n",
    "grouped    = data_t.groupby(by=['New ID'])\n",
    "max_length = grouped.count()['Delta'].max() #max_length = 48\n",
    "\n",
    "xt         = np.zeros([len(id_list), max_length, len(feat_timevarying)])\n",
    "for i, pid in enumerate(id_list):\n",
    "    tmp    = np.asarray(grouped.get_group(pid))[:, 1:]\n",
    "    xt[i, :np.shape(tmp)[0], :] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list    = time['New ID'].unique()\n",
    "grouped    = time.groupby(by=['New ID'])\n",
    "\n",
    "t          = np.zeros([len(id_list), max_length, 1])\n",
    "for i, pid in enumerate(id_list):\n",
    "    tmp    = np.asarray(grouped.get_group(pid))[:, 1:]\n",
    "    t[i, :np.shape(tmp)[0], :] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y   = np.asarray(label[['Coding.3']])\n",
    "tte = np.asarray(label[['Days since diagnosis.3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "np.savez(\n",
    "    f'./data/processed/final/{out_dir}/dataset.npz',\n",
    "    data_xs   = xs,\n",
    "    data_xt   = xt,\n",
    "    data_time = t,\n",
    "    data_y    = y,\n",
    "    data_tte  = tte,\n",
    "    feat_static = feat_static,\n",
    "    feat_timevarying = feat_timevarying,\n",
    "    \n",
    "    xt_bin_list = xt_bin_list,\n",
    "    xt_con_list = xt_con_list\n",
    ")\n",
    "\n",
    "pickle.dump(scaler_s, open(f'./data/processed/final/{out_dir}/scaler_s.pkl', 'wb'))\n",
    "pickle.dump(scaler_t, open(f'./data/processed/final/{out_dir}/scaler_t.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
