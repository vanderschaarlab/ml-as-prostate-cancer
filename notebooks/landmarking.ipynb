{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "_EPSILON = 1e-08\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os,sys\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sksurv.metrics import concordance_index_ipcw, concordance_index_censored, brier_score\n",
    "\n",
    "\n",
    "from models.benchmarks import LANDMARKING\n",
    "from helpers.data_loader import *\n",
    "\n",
    "\n",
    "# sys.path.append('../..')\n",
    "# import utils_network as utils\n",
    "# from utils_eval import weighted_c_index, weighted_brier_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_ITERATION               = 5\n",
    "MICE_IMPUTED_DATA_VERSION   = False\n",
    "data_mode                   = 'STRATCANS_v1_new2'\\\n",
    "    + ('_MICE' if MICE_IMPUTED_DATA_VERSION else '')\n",
    "landmarking_mode            = 'CoxPH' #{CoxPH, RSForest}\n",
    "\n",
    "seed                        = 1234\n",
    "\n",
    "(data_xs, data_xt, data_time, data_y, data_tte), \\\n",
    "(feat_static, feat_timevarying), \\\n",
    "(xt_bin_list, xt_con_list) = \\\n",
    "import_dataset_STRATCANS_v1(mice_version=MICE_IMPUTED_DATA_VERSION)\n",
    "    \n",
    "data_xs           = data_xs[:, [0,1,2,3,4,5,6]]\n",
    "feat_static       = feat_static[[0,1,2,3,4,5,6]]\n",
    "\n",
    "data_xt           = data_xt[:, :, [0,1,2,3,6,7,8,9,10]]\n",
    "feat_timevarying  = feat_timevarying[[0,1,2,3,6,7,8,9,10]]\n",
    "xt_con_list       = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "x_dim_static      = len(feat_static)\n",
    "x_dim_timevarying = len(feat_timevarying) # this includes delta\n",
    "\n",
    "max_length                  = np.shape(data_time)[1]\n",
    "num_Event                   = len(np.unique(data_y)) - 1  #number of next outcome events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = dict()\n",
    "\n",
    "if landmarking_mode == 'CoxPH':\n",
    "    hyperparameters['alpha'] = 0.001\n",
    "elif landmarking_mode == 'RSForest':\n",
    "    hyperparameters['n_estimators'] =100\n",
    "else:\n",
    "    raise ValueError(\"Wrong survival model. Select {'CoxPH', 'RSForest'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============LANDMARKING-CoxPH | OUT ITERATION: 0====================\n",
      "Training 1-th Landmarking Model at 0 - #468\n",
      "Training 2-th Landmarking Model at 365 - #426\n",
      "Training 3-th Landmarking Model at 730 - #366\n",
      "Training 4-th Landmarking Model at 1095 - #306\n",
      "===============LANDMARKING-CoxPH | OUT ITERATION: 1====================\n",
      "Training 1-th Landmarking Model at 0 - #468\n",
      "Training 2-th Landmarking Model at 365 - #428\n",
      "Training 3-th Landmarking Model at 730 - #360\n",
      "Training 4-th Landmarking Model at 1095 - #307\n",
      "===============LANDMARKING-CoxPH | OUT ITERATION: 2====================\n",
      "Training 1-th Landmarking Model at 0 - #468\n",
      "Training 2-th Landmarking Model at 365 - #429\n",
      "Training 3-th Landmarking Model at 730 - #364\n",
      "Training 4-th Landmarking Model at 1095 - #306\n",
      "===============LANDMARKING-CoxPH | OUT ITERATION: 3====================\n",
      "Training 1-th Landmarking Model at 0 - #468\n",
      "Training 2-th Landmarking Model at 365 - #423\n",
      "Training 3-th Landmarking Model at 730 - #363\n",
      "Training 4-th Landmarking Model at 1095 - #306\n",
      "===============LANDMARKING-CoxPH | OUT ITERATION: 4====================\n",
      "Training 1-th Landmarking Model at 0 - #468\n",
      "Training 2-th Landmarking Model at 365 - #430\n",
      "Training 3-th Landmarking Model at 730 - #357\n",
      "Training 4-th Landmarking Model at 1095 - #296\n"
     ]
    }
   ],
   "source": [
    "LANDMARKING_TIMES = [0, 365, 365*2, 365*3]\n",
    "\n",
    "PRED_TIMES = [0, 365, 365*2, 365*3]\n",
    "EVAL_TIMES = [365, 365*2, 365*3, 365*4, 365*5, 365*6, 365*7, 365*8, 365*9, 365*10]\n",
    "# EVAL_TIMES = [365, 365*2, 365*3, 365*4, 365*5, 365*6, 365*7, 365*8, 365*9, 365*10]\n",
    "\n",
    "\n",
    "FINAL_RESULT1 = np.zeros([OUT_ITERATION, len(PRED_TIMES), len(EVAL_TIMES)])\n",
    "FINAL_RESULT2 = np.zeros([OUT_ITERATION, len(PRED_TIMES), len(EVAL_TIMES)])\n",
    "\n",
    "FINAL_RESULT1_pred = np.zeros([OUT_ITERATION, len(PRED_TIMES), len(EVAL_TIMES)])\n",
    "FINAL_RESULT2_pred = np.zeros([OUT_ITERATION, len(PRED_TIMES), len(EVAL_TIMES)])\n",
    "\n",
    "# for out_itr in range(1):\n",
    "for out_itr in range(OUT_ITERATION):\n",
    "    \n",
    "    print('===============LANDMARKING-{} | OUT ITERATION: {}===================='.format(landmarking_mode, out_itr))\n",
    "\n",
    "    (tr_data_s,te_data_s, tr_data_t,te_data_t, tr_time,te_time, tr_tte,te_tte, tr_label,te_label) = train_test_split(\n",
    "        data_xs, data_xt, data_time, data_tte, data_y, test_size=0.2, random_state=seed+out_itr\n",
    "    ) \n",
    "\n",
    "    save_path = './{}/Landmarking/{}/itr{}'.format(data_mode, landmarking_mode, out_itr)\n",
    "\n",
    "    if not os.path.exists(save_path + '/models/'):\n",
    "        os.makedirs(save_path + '/models/')\n",
    "\n",
    "    if not os.path.exists(save_path + '/results/'):\n",
    "        os.makedirs(save_path + '/results/')\n",
    "\n",
    "    ##### TRAINING\n",
    "    landmarking = LANDMARKING(LANDMARKING_TIMES=LANDMARKING_TIMES, LANDMARKING_MODE=landmarking_mode, parameters=hyperparameters)\n",
    "    landmarking.train(tr_data_s, tr_data_t, tr_time, tr_tte, tr_label)\n",
    "    \n",
    "\n",
    "    with open(save_path + '/models/landmarking_model.pkl', 'wb') as out_path:\n",
    "        pickle.dump(landmarking, out_path)\n",
    "\n",
    "\n",
    "    ##### TESTING\n",
    "    with open(save_path + '/models/landmarking_model.pkl', 'rb') as in_path:\n",
    "        landmarking = pickle.load(in_path)    \n",
    "    te_pred = landmarking.predict(te_data_s, te_data_t, te_time, EVAL_TIMES)\n",
    "\n",
    "\n",
    "    RESULT1 = -1. * np.ones([len(PRED_TIMES), len(EVAL_TIMES)])\n",
    "    RESULT2 = -1. * np.ones([len(PRED_TIMES), len(EVAL_TIMES)])\n",
    "\n",
    "    for p_idx, pred_time in enumerate(PRED_TIMES):\n",
    "        p_idx_te  = te_tte >= pred_time\n",
    "        p_idx_tr  = tr_tte >= pred_time\n",
    "\n",
    "        tmp_pred = landmarking.predict_predtime(te_data_s, te_data_t, te_time, pred_time, EVAL_TIMES)\n",
    "\n",
    "        tmp_y = tr_label[p_idx_tr]\n",
    "        tmp_t = tr_tte[p_idx_tr] - pred_time\n",
    "\n",
    "        tr_y_structured =  [(tmp_y[i], tmp_t[i]) for i in range(len(tmp_y))]\n",
    "        tr_y_structured = np.array(tr_y_structured, dtype=[('status', 'bool'),('time','<f8')])\n",
    "\n",
    "        tmp_y = te_label[p_idx_te]\n",
    "        tmp_t = te_tte[p_idx_te] - pred_time\n",
    "\n",
    "        te_y_structured =  [(tmp_y[i], tmp_t[i]) for i in range(len(tmp_y))]\n",
    "        te_y_structured = np.array(te_y_structured, dtype=[('status', 'bool'),('time','<f8')])\n",
    "\n",
    "\n",
    "        for e_idx, eval_time in enumerate(EVAL_TIMES):\n",
    "            if np.sum((tmp_t<=eval_time) & (tmp_y==1)) > 0:\n",
    "                RESULT1[p_idx, e_idx] = concordance_index_ipcw(tr_y_structured, te_y_structured, tmp_pred[p_idx_te][:, e_idx], tau=eval_time)[0]\n",
    "                RESULT2[p_idx, e_idx] = brier_score(tr_y_structured, te_y_structured, 1.- tmp_pred[p_idx_te][:, e_idx], times=eval_time)[1][0]\n",
    "\n",
    "    pd.DataFrame(RESULT1, index=PRED_TIMES, columns=EVAL_TIMES).to_csv(save_path+'/results/c_index.csv')\n",
    "    pd.DataFrame(RESULT2, index=PRED_TIMES, columns=EVAL_TIMES).to_csv(save_path+'/results/brier_score.csv')\n",
    "    \n",
    "    FINAL_RESULT1[out_itr, :, :] = RESULT1\n",
    "    FINAL_RESULT2[out_itr, :, :] = RESULT2\n",
    "    \n",
    "    \n",
    "    RESULT1 = -1. * np.ones([len(PRED_TIMES), len(EVAL_TIMES)])\n",
    "    RESULT2 = -1. * np.ones([len(PRED_TIMES), len(EVAL_TIMES)])\n",
    "\n",
    "    for p_idx, pred_time in enumerate(PRED_TIMES):\n",
    "        p_idx_te  = te_tte >= 0\n",
    "        p_idx_tr  = tr_tte >= 0\n",
    "\n",
    "        tmp_pred = landmarking.predict_predtime(te_data_s, te_data_t, te_time, pred_time, EVAL_TIMES)\n",
    "\n",
    "        tmp_y = tr_label[p_idx_tr]\n",
    "        tmp_t = tr_tte[p_idx_tr] - 0\n",
    "\n",
    "        tr_y_structured =  [(tmp_y[i], tmp_t[i]) for i in range(len(tmp_y))]\n",
    "        tr_y_structured = np.array(tr_y_structured, dtype=[('status', 'bool'),('time','<f8')])\n",
    "\n",
    "        tmp_y = te_label[p_idx_te]\n",
    "        tmp_t = te_tte[p_idx_te] - 0\n",
    "\n",
    "        te_y_structured =  [(tmp_y[i], tmp_t[i]) for i in range(len(tmp_y))]\n",
    "        te_y_structured = np.array(te_y_structured, dtype=[('status', 'bool'),('time','<f8')])\n",
    "\n",
    "        for e_idx, eval_time in enumerate(EVAL_TIMES):\n",
    "            if np.sum((tmp_t<=eval_time) & (tmp_y==1)) > 0:\n",
    "                RESULT1[p_idx, e_idx] = concordance_index_ipcw(tr_y_structured, te_y_structured, tmp_pred[p_idx_te][:, e_idx], tau=eval_time)[0]\n",
    "                RESULT2[p_idx, e_idx] = brier_score(tr_y_structured, te_y_structured, 1.- tmp_pred[p_idx_te][:, e_idx], times=eval_time)[1][0]\n",
    "\n",
    "    pd.DataFrame(RESULT1, index=PRED_TIMES, columns=EVAL_TIMES).to_csv(save_path+'/results/c_index_pred.csv')\n",
    "    pd.DataFrame(RESULT2, index=PRED_TIMES, columns=EVAL_TIMES).to_csv(save_path+'/results/brier_score_pred.csv')\n",
    "    \n",
    "    FINAL_RESULT1_pred[out_itr, :, :] = RESULT1\n",
    "    FINAL_RESULT2_pred[out_itr, :, :] = RESULT2\n",
    "    \n",
    "FINAL_RESULT1[FINAL_RESULT1 == -1] = np.nan\n",
    "FINAL_RESULT2[FINAL_RESULT2 == -1] = np.nan\n",
    "\n",
    "pd.DataFrame(np.nanmean(FINAL_RESULT1, axis=0), index=PRED_TIMES, columns=EVAL_TIMES).to_csv('./{}/Landmarking/{}/final_c_index_mean.csv'.format(data_mode, landmarking_mode))\n",
    "pd.DataFrame(np.nanmean(FINAL_RESULT2, axis=0), index=PRED_TIMES, columns=EVAL_TIMES).to_csv('./{}/Landmarking/{}/final_brier_score_mean.csv'.format(data_mode, landmarking_mode))\n",
    "\n",
    "pd.DataFrame(np.nanstd(FINAL_RESULT1, axis=0), index=PRED_TIMES, columns=EVAL_TIMES).to_csv('./{}/Landmarking/{}/final_c_index_std.csv'.format(data_mode, landmarking_mode))\n",
    "pd.DataFrame(np.nanstd(FINAL_RESULT2, axis=0), index=PRED_TIMES, columns=EVAL_TIMES).to_csv('./{}/Landmarking/{}/final_brier_score_std.csv'.format(data_mode, landmarking_mode))\n",
    "\n",
    "\n",
    "FINAL_RESULT1_pred[FINAL_RESULT1_pred == -1] = np.nan\n",
    "FINAL_RESULT2_pred[FINAL_RESULT2_pred == -1] = np.nan\n",
    "\n",
    "pd.DataFrame(np.nanmean(FINAL_RESULT1_pred, axis=0), index=PRED_TIMES, columns=EVAL_TIMES).to_csv('./{}/Landmarking/{}/final_c_index_pred_mean.csv'.format(data_mode, landmarking_mode))\n",
    "pd.DataFrame(np.nanmean(FINAL_RESULT2_pred, axis=0), index=PRED_TIMES, columns=EVAL_TIMES).to_csv('./{}/Landmarking/{}/final_brier_score_pred_mean.csv'.format(data_mode, landmarking_mode))\n",
    "\n",
    "pd.DataFrame(np.nanstd(FINAL_RESULT1_pred, axis=0), index=PRED_TIMES, columns=EVAL_TIMES).to_csv('./{}/Landmarking/{}/final_c_index_pred_std.csv'.format(data_mode, landmarking_mode))\n",
    "pd.DataFrame(np.nanstd(FINAL_RESULT2_pred, axis=0), index=PRED_TIMES, columns=EVAL_TIMES).to_csv('./{}/Landmarking/{}/final_brier_score_pred_std.csv'.format(data_mode, landmarking_mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_RESULT1[FINAL_RESULT1 == -1] = np.nan\n",
    "FINAL_RESULT2[FINAL_RESULT2 == -1] = np.nan\n",
    "\n",
    "pd.DataFrame(np.nanmean(FINAL_RESULT1, axis=0), index=PRED_TIMES, columns=EVAL_TIMES).to_csv('./{}/Landmarking/{}/final_c_index.csv'.format(data_mode, landmarking_mode))\n",
    "pd.DataFrame(np.nanmean(FINAL_RESULT2, axis=0), index=PRED_TIMES, columns=EVAL_TIMES).to_csv('./{}/Landmarking/{}/final_brier_score.csv'.format(data_mode, landmarking_mode))\n",
    "\n",
    "\n",
    "FINAL_RESULT1_pred[FINAL_RESULT1_pred == -1] = np.nan\n",
    "FINAL_RESULT2_pred[FINAL_RESULT2_pred == -1] = np.nan\n",
    "\n",
    "pd.DataFrame(np.nanmean(FINAL_RESULT1_pred, axis=0), index=PRED_TIMES, columns=EVAL_TIMES).to_csv('./{}/Landmarking/{}/final_c_index_pred.csv'.format(data_mode, landmarking_mode))\n",
    "pd.DataFrame(np.nanmean(FINAL_RESULT2_pred, axis=0), index=PRED_TIMES, columns=EVAL_TIMES).to_csv('./{}/Landmarking/{}/final_brier_score_pred.csv'.format(data_mode, landmarking_mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
