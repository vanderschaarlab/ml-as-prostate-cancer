{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_EPSILON = 1e-08\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s  = pd.read_csv('./data/processed/after imputation/baseline.csv')\n",
    "df_t  = pd.read_csv('./data/processed/after imputation/temporal.csv')\n",
    "df_t  = df_t.drop_duplicates(subset=['New ID', 'Days Since Diagnosis'], keep='last').reset_index(drop=True)\n",
    "\n",
    "df_t1  = pd.read_csv('./data/processed/after imputation/repeat_psa.csv')\n",
    "df_t2  = pd.read_csv('./data/processed/after imputation/repeat_mri.csv')\n",
    "df_t3  = pd.read_csv('./data/processed/after imputation/repeat_biopsy.csv')\n",
    "\n",
    "df_t1  = df_t1.drop_duplicates(subset=['New ID', 'Days Since Diagnosis'], keep='last').reset_index(drop=True)\n",
    "df_t2  = df_t2.drop_duplicates(subset=['New ID', 'Days Since Diagnosis'], keep='last').reset_index(drop=True)\n",
    "df_t3  = df_t3.drop_duplicates(subset=['New ID', 'Days Since Diagnosis'], keep='last').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = df_t.drop_duplicates(subset=['New ID',], keep='first')[['Days Since Diagnosis']]\n",
    "diff  = df_t['Days Since Diagnosis'].diff()\n",
    "diff[first.index] = first['Days Since Diagnosis']\n",
    "\n",
    "time  = df_t[['New ID', 'Days Since Diagnosis']]\n",
    "\n",
    "df_t['Days Since Diagnosis'] = diff\n",
    "df_t = df_t.rename(columns={'Days Since Diagnosis': 'Delta'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = df_t1.drop_duplicates(subset=['New ID',], keep='first')[['Days Since Diagnosis']]\n",
    "diff  = df_t1['Days Since Diagnosis'].diff()\n",
    "diff[first.index] = first['Days Since Diagnosis']\n",
    "\n",
    "time1 = df_t1[['New ID', 'Days Since Diagnosis']]\n",
    "\n",
    "df_t1['Days Since Diagnosis'] = diff\n",
    "df_t1 = df_t1.rename(columns={'Days Since Diagnosis': 'Delta'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = df_t2.drop_duplicates(subset=['New ID',], keep='first')[['Days Since Diagnosis']]\n",
    "diff  = df_t2['Days Since Diagnosis'].diff()\n",
    "diff[first.index] = first['Days Since Diagnosis']\n",
    "\n",
    "time2 = df_t2[['New ID', 'Days Since Diagnosis']]\n",
    "\n",
    "df_t2['Days Since Diagnosis'] = diff\n",
    "df_t2 = df_t2.rename(columns={'Days Since Diagnosis': 'Delta'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = df_t3.drop_duplicates(subset=['New ID',], keep='first')[['Days Since Diagnosis']]\n",
    "diff  = df_t3['Days Since Diagnosis'].diff()\n",
    "diff[first.index] = first['Days Since Diagnosis']\n",
    "\n",
    "time3 = df_t3[['New ID', 'Days Since Diagnosis']]\n",
    "\n",
    "df_t3['Days Since Diagnosis'] = diff\n",
    "df_t3 = df_t3.rename(columns={'Days Since Diagnosis': 'Delta'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_static = [\n",
    "    'Exact age at diagnosis', 'Number of negative biopsies before diagnosis',\n",
    "    'Number of MRI-visible lesions', 'Ethnicity', 'Family History of Prostate Cancer',\n",
    "    'CPG', 'PI-RADS score', 'STRATCANS (simplified)',\n",
    "]\n",
    "\n",
    "feat_timevarying1 = [\n",
    "     'Delta', 'Repeat PSA'\n",
    "]\n",
    "\n",
    "feat_timevarying2 = [\n",
    "     'Delta', 'Repeat MRI PRECISE Scoring', 'Repeat MRI Stage','Repeat MRI Volume', 'Repeat MRI PSAd'\n",
    "]\n",
    "\n",
    "feat_timevarying3 = [\n",
    "     'Delta', 'Repeat Biopsy Core Total', 'Repeat Biopsy Core Positive', \n",
    "#      'Repeat Biopsy Primary Gleason', 'Repeat Biopsy Secondary Gleason', \n",
    "     'Repeat Biopsy Grade Group'\n",
    "]\n",
    "\n",
    "feat_label = [\n",
    "    'Coding.3', 'Days since diagnosis.3'\n",
    "]\n",
    "\n",
    "\n",
    "# xt_bin_list = []\n",
    "# xt_con_list = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "\n",
    "data_s = df_s[['New ID'] + feat_static]\n",
    "\n",
    "data_t1 = df_t1[['New ID'] + feat_timevarying1]\n",
    "data_t2 = df_t2[['New ID'] + feat_timevarying2]\n",
    "data_t3 = df_t3[['New ID'] + feat_timevarying3]\n",
    "\n",
    "label   = df_s[['New ID'] + feat_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = np.unique(data_t1['New ID'].unique().tolist() + data_t2['New ID'].unique().tolist() + data_t3['New ID'].unique().tolist())\n",
    "\n",
    "data_s  = data_s[data_s['New ID'].isin(id_list)].reset_index(drop=True)\n",
    "label   = label[label['New ID'].isin(id_list)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vdslab/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "/home/vdslab/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/vdslab/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/vdslab/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_s                 = MinMaxScaler()\n",
    "scaler_t1                 = MinMaxScaler()\n",
    "scaler_t2                 = MinMaxScaler()\n",
    "scaler_t3                 = MinMaxScaler()\n",
    "\n",
    "data_t1.loc[data_t1['Delta'] == 0, 'Delta'] = 1. #0 makes -inf!\n",
    "data_t1['Delta']          = np.log(data_t1['Delta'])  ### this is to deal with very skewed deltas...\n",
    "\n",
    "data_t2.loc[data_t2['Delta'] == 0, 'Delta'] = 1. #0 makes -inf!\n",
    "data_t2['Delta']          = np.log(data_t2['Delta'])  ### this is to deal with very skewed deltas...\n",
    "\n",
    "data_t3.loc[data_t3['Delta'] == 0, 'Delta'] = 1. #0 makes -inf!\n",
    "data_t3['Delta']          = np.log(data_t3['Delta'])  ### this is to deal with very skewed deltas...\n",
    "\n",
    "\n",
    "data_s[feat_static]      = scaler_s.fit_transform(data_s[feat_static])\n",
    "data_t1[feat_timevarying1] = scaler_t1.fit_transform(data_t1[feat_timevarying1])\n",
    "data_t2[feat_timevarying2] = scaler_t2.fit_transform(data_t2[feat_timevarying2])\n",
    "data_t3[feat_timevarying3] = scaler_t3.fit_transform(data_t3[feat_timevarying3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs     = np.asarray(data_s)[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped     = data_t1.groupby(by=['New ID'])\n",
    "max_length  = grouped.count()['Delta'].max() #max_length = 48\n",
    "\n",
    "xt1         = np.zeros([len(id_list), max_length, len(feat_timevarying1)])\n",
    "for i, pid in enumerate(id_list):\n",
    "    tmp    = np.asarray(grouped.get_group(pid))[:, 1:]\n",
    "    xt1[i, :np.shape(tmp)[0], :] = tmp\n",
    "    \n",
    "    \n",
    "grouped    = time1.groupby(by=['New ID'])\n",
    "\n",
    "t1          = np.zeros([len(id_list), max_length])\n",
    "for i, pid in enumerate(id_list):\n",
    "    tmp    = np.asarray(grouped.get_group(pid))[:, 1:]\n",
    "    t1[i, :np.shape(tmp)[0]] = tmp[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped     = data_t2.groupby(by=['New ID'])\n",
    "max_length  = grouped.count()['Delta'].max() #max_length = 48\n",
    "\n",
    "xt2         = np.zeros([len(id_list), max_length, len(feat_timevarying2)])\n",
    "for i, pid in enumerate(id_list):\n",
    "    tmp    = np.asarray(grouped.get_group(pid))[:, 1:]\n",
    "    xt2[i, :np.shape(tmp)[0], :] = tmp\n",
    "    \n",
    "    \n",
    "grouped    = time2.groupby(by=['New ID'])\n",
    "\n",
    "t2          = np.zeros([len(id_list), max_length])\n",
    "for i, pid in enumerate(id_list):\n",
    "    tmp    = np.asarray(grouped.get_group(pid))[:, 1:]\n",
    "    t2[i, :np.shape(tmp)[0]] = tmp[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped     = data_t3.groupby(by=['New ID'])\n",
    "max_length  = grouped.count()['Delta'].max() \n",
    "\n",
    "xt3         = np.zeros([len(id_list), max_length, len(feat_timevarying3)])\n",
    "for i, pid in enumerate(id_list):\n",
    "    tmp    = np.asarray(grouped.get_group(pid))[:, 1:]\n",
    "    xt3[i, :np.shape(tmp)[0], :] = tmp\n",
    "    \n",
    "    \n",
    "grouped    = time3.groupby(by=['New ID'])\n",
    "\n",
    "t3          = np.zeros([len(id_list), max_length])\n",
    "for i, pid in enumerate(id_list):\n",
    "    tmp    = np.asarray(grouped.get_group(pid))[:, 1:]\n",
    "    t3[i, :np.shape(tmp)[0]] = tmp[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y   = np.asarray(label[['Coding.3']])\n",
    "tte = np.asarray(label[['Days since diagnosis.3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "np.savez(\n",
    "    './data/processed/final/version2 (separate)/dataset.npz',\n",
    "    data_xs   = xs,\n",
    "    \n",
    "    data_xt1   = xt1,\n",
    "    data_xt2   = xt2,\n",
    "    data_xt3   = xt3,\n",
    "    \n",
    "    data_time1 = t1,\n",
    "    data_time2 = t2,\n",
    "    data_time3 = t3,\n",
    "    \n",
    "    data_y    = y,\n",
    "    data_tte  = tte,\n",
    "    feat_static = feat_static,\n",
    "    \n",
    "    feat_timevarying1 = feat_timevarying1,\n",
    "    feat_timevarying2 = feat_timevarying2,\n",
    "    feat_timevarying3 = feat_timevarying3,\n",
    ")\n",
    "\n",
    "pickle.dump(scaler_s, open('./data/processed/final/version2 (separate)/scaler_s.pkl', 'wb'))\n",
    "pickle.dump(scaler_t1, open('./data/processed/final/version2 (separate)/scaler_t1.pkl', 'wb'))\n",
    "pickle.dump(scaler_t2, open('./data/processed/final/version2 (separate)/scaler_t2.pkl', 'wb'))\n",
    "pickle.dump(scaler_t3, open('./data/processed/final/version2 (separate)/scaler_t3.pkl', 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
